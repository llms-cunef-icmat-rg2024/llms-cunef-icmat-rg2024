{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Formal Algorithms for Transformers\"\n",
        "author: \"Roi Naveiro (CUNEF University)\"\n",
        "format:\n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    chalkboard: \n",
        "      buttons: false\n",
        "    preview-links: auto\n",
        "    css: styles.css\n",
        "    #footer: <https://roinaveiro.github.io>\n",
        "resources:\n",
        "  - demo.pdf\n",
        "---"
      ],
      "id": "90a6a840"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ],
      "id": "d272b5fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Methodological Contributions\n",
        "\n",
        "* Automatic Differentiation\n",
        "\n",
        "* Stochastic Gradient Descent\n",
        "\n",
        "* Architectures \n",
        "  * MLP\n",
        "  * CNN, RNN\n",
        "  * Attention Mechanism\n",
        "\n",
        "## Transformers\n",
        "\n",
        "> \"The transformer model has been proven to be superior in quality for many sequence-to-sequence tasks while being more parallelizable. The transformer model follows the encoder-decoder architecture using self-attention mechanisms. The self-attention mechanism allows the transformer to weigh the importance of other words in the sentence when encoding or decoding a particular word.\"\n",
        "\n",
        "â€” Source: [Google Developers](https://developers.google.com/machine-learning/glossary#transformer_model)\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "## Notation\n",
        "\n",
        "* Vocabulary: $V$, is a finite set identified with $[N_V] \\equiv \\lbrace 1, \\dots, N_V\\rbrace$.\n",
        "\n",
        "* Letters, words, most commonly subwords.\n",
        "\n",
        "* Sequence: $\\boldsymbol{x} \\equiv x[1:l] = x[1] \\dots x[$\\ell$]$\n",
        "\n",
        "* $\\ell_{\\text{max}}$: maximum length of a sequence.\n",
        "\n",
        "## Transformers Tasks - Sequence Modeling\n",
        "\n",
        "## Transformers Tasks - Sequence-to-Sequence Modeling\n",
        "\n",
        "## Transformers Tasks - Sequence Classification\n",
        "\n",
        "## Tokenization\n",
        "\n",
        "* Character-level tokenization\n",
        "* Word-level tokenization\n",
        "* Subword-level tokenization\n",
        "\n",
        "## Tokenization - Word-level\n"
      ],
      "id": "c38979f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# This is a Python code chunk that won't run\n",
        "def hello_world():\n",
        "    print(\"Hello, world!\")"
      ],
      "id": "efb2afa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architectural Components\n",
        "\n",
        "## Token Embedding\n",
        "\n",
        "## Positional Embedding\n",
        "\n",
        "## Attention  \n",
        "\n",
        "## Multi-Head Attention\n",
        "\n",
        "## Things to understand\n",
        "\n",
        "* Permutation Equivariance \n",
        "\n",
        "* Positional Encoding: The transformer model does not have any built-in understanding of the order of the words in a sequence. To give the model some information about the relative or absolute position of the words in the sequence, we add positional encoding to the input embeddings.\n",
        "\n",
        "* Residual connections: Residual connections are simply adding the input of the layer to it output. For example, we add the initial embedding to the output of the attention. Residual connections mitigate the vanishing gradient problem. The intuition is that if the gradient is too small, we can just add the input to the output and the gradient will be larger.\n",
        "\n",
        "* Layer normalization in embedding dimension: Layer normalization is a technique to normalize the inputs of a layer in such a way that the mean is 0 and the variance is 1. This helps to stabilize the training of the model.\n",
        "\n",
        "  * Stability: Layer normalization stabilizes the learning process by normalizing the inputs to each layer to have a mean of 0 and a variance of 1. This reduces the chance of the values either vanishing (becoming too small) or exploding (becoming too large), which can cause the model to stop learning.\n",
        "\n",
        "  * Regularization: Layer normalization also acts as a form of regularization, reducing overfitting. This is because it adds noise to the hidden states during training, which helps the model generalize better to unseen data.\n",
        "\n",
        "  * Speed: Layer normalization can also make the training process faster, because it allows for higher learning rates and less careful initialization.\n"
      ],
      "id": "bc84acbb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}